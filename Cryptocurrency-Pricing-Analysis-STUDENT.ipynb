{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Data-Driven Approach To Cryptocurrency Speculation\n",
    "\n",
    "*How do Bitcoin markets behave? What are the causes of the sudden spikes and dips in cryptocurrency values?  Are the markets for different altcoins, such as Litecoin and Ripple, inseparably linked or largely independent?  **How can we predict what will happen next?***\n",
    "\n",
    "Articles on cryptocurrencies, such as Bitcoin and Ethereum, are rife with speculation these days, with hundreds of self-proclaimed experts advocating for the trends that they expect to emerge.  What is lacking from many of these analyses is a strong data analysis foundation to backup the claims. \n",
    "\n",
    "The goal of this article is to provide an easy introduction to cryptocurrency analysis using Python.  We will walk through a simple Python script to retrieve, analyze, and visualize data on different cryptocurrencies.  In the process, we will uncover an interesting trend in how these volatile markets behave, and how they are evolving.\n",
    "\n",
    "<img id=\"altcoin_prices_combined_0\" src=\"https://cdn.patricktriest.com/blog/images/posts/crypto-markets/plot-images/altcoin_prices_combined.png\" alt=\"Combined Altcoin Prices\">\n",
    "\n",
    "This is not a post explaining what cryptocurrencies are (if you want one, I would recommend <a href=\"https://medium.com/tradecraft-traction/blockchain-for-the-rest-of-us-c3fc5e42254f\" target=\"_blank\" rel=\"noopener\">this great overview</a>), nor is it an opinion piece on which specific currencies will rise and which will fall.  Instead, all that we are concerned about in this tutorial is procuring the raw data and uncovering the stories hidden in the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've got a blank Jupyter notebook open, the first thing we'll do is import the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:43.865044Z",
     "start_time": "2017-12-06T08:00:43.650958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import quandl\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also import Plotly and enable the offline mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:46.297247Z",
     "start_time": "2017-12-06T08:00:45.000639Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:46.304393Z",
     "start_time": "2017-12-06T08:00:46.300116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = os.environ['QUANDL_API_KEY']\n",
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Bitcoin Pricing Data\n",
    "Now that everything is set up, we're ready to start retrieving data for analysis.  First, we need to get Bitcoin pricing data using [Quandl's free Bitcoin API](https://blog.quandl.com/api-for-bitcoin-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Quandl Helper Function\n",
    "To assist with this data retrieval we'll define a function to download and cache datasets from Quandl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:47.734872Z",
     "start_time": "2017-12-06T08:00:47.708251Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quandl_data(quandl_id):\n",
    "    '''Download and cache Quandl dataseries'''\n",
    "    cache_path = '{}{}.pkl'.format(data_dir, quandl_id.replace('/','-'))\n",
    "    try:\n",
    "        f = open(cache_path, 'rb')\n",
    "        df = pickle.load(f)   \n",
    "        print('Loaded {} from cache'.format(quandl_id))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {} from Quandl'.format(quandl_id))\n",
    "        df = quandl.get(quandl_id, returns=\"pandas\")\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(quandl_id, cache_path))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using `pickle` to serialize and save the downloaded data as a file, which will prevent our script from re-downloading the same data each time we run the script.  The function will return the data as a [Pandas]('http://pandas.pydata.org/') dataframe.  If you're not familiar with dataframes, you can think of them as super-powered Python spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Kraken Exchange Pricing Data\n",
    "Let's first pull the historical Bitcoin exchange rate for the [Kraken](https://www.kraken.com/) Bitcoin exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:52.365480Z",
     "start_time": "2017-12-06T08:00:49.064424Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull Kraken BTC price exchange data\n",
    "btc_usd_price_kraken = get_quandl_data('BCHARTS/KRAKENUSD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the first 5 rows of the dataframe using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:52.404442Z",
     "start_time": "2017-12-06T08:00:52.371323Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#***YOUR CODE HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll generate a simple chart as a quick visual verification that the data looks correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:00:52.536728Z",
     "start_time": "2017-12-06T08:00:52.407896Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chart the BTC pricing data\n",
    "btc_trace = go.Scatter(x=\"...\", y=\"...\")\n",
    "py.iplot([btc_trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're using [Plotly](https://plot.ly/) for generating our visualizations.  This is a less traditional choice than some of the more established Python data visualization libraries such as [Matplotlib](https://matplotlib.org/), but I think Plotly is a great choice since it produces fully-interactive charts using [D3.js](https://d3js.org/).  These charts have attractive visual defaults, are easy to explore, and are very simple to embed in web pages.\n",
    "\n",
    "> As a quick sanity check, you should compare the generated chart with publically available graphs on Bitcoin prices(such as those on [Coinbase](https://www.coinbase.com/dashboard)), to verify that the downloaded data is legit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Pricing Data From More BTC Exchanges\n",
    "You might have noticed a hitch in this dataset - there are a few notable down-spikes, particularly in late 2014 and early 2016.  These spikes are specific to the Kraken dataset, and we obviously don't want them to be reflected in our overall pricing analysis.  \n",
    "\n",
    "The nature of Bitcoin exchanges is that the pricing is determined by supply and demand, hence no single exchange contains a true \"master price\" of Bitcoin.  To solve this issue, along with that of down-spikes, we'll pull data from three more major Bitcoin changes to calculate an aggregate Bitcoin price index.\n",
    "\n",
    "First, we will download the data from each exchange into a dictionary of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:00.895278Z",
     "start_time": "2017-12-06T08:00:52.540311Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull pricing data for 3 more BTC exchanges\n",
    "exchanges = ['COINBASE','BITSTAMP','ITBIT']\n",
    "\n",
    "exchange_data = {}\n",
    "\n",
    "exchange_data['KRAKEN'] = btc_usd_price_kraken\n",
    "\n",
    "for exchange in exchanges:\n",
    "    exchange_code = 'BCHARTS/{}USD'.format(exchange)\n",
    "    btc_exchange_df = get_quandl_data(exchange_code)\n",
    "    exchange_data[exchange] = btc_exchange_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge All Of The Pricing Data Into A Single Dataframe\n",
    "Next, we will define a simple function to merge a common column of each dataframe into a new combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:00.910689Z",
     "start_time": "2017-12-06T08:01:00.898799Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dfs_on_column(dataframes, labels, col):\n",
    "    '''Merge a single column of each dataframe into a new combined dataframe'''\n",
    "    series_dict = {}\n",
    "    for index in range(len(dataframes)):\n",
    "        series_dict[labels[index]] = dataframes[index][col]\n",
    "        \n",
    "    return pd.DataFrame(series_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will merge all of the dataframes together on their \"Weighted Price\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:00.929799Z",
     "start_time": "2017-12-06T08:01:00.914139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the BTC price dataseries' into a single dataframe\n",
    "btc_usd_datasets = merge_dfs_on_column(list(exchange_data.values()), list(exchange_data.keys()), 'Weighted Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can preview last five rows the result using the `tail()` method, to make sure it looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:00.948639Z",
     "start_time": "2017-12-06T08:01:00.932765Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#***YOUR CODE HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize The Pricing Datasets\n",
    "The next logical step is to visualize how these pricing datasets compare.  For this, we'll define a helper function to provide a single-line command to compare each column in the dataframe on a graph using Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:01.033125Z",
     "start_time": "2017-12-06T08:01:00.952460Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_scatter(df, title, seperate_y_axis=False, y_axis_label='', scale='linear', initial_hide=False):\n",
    "    '''Generate a scatter plot of the entire dataframe'''\n",
    "    label_arr = list(df)\n",
    "    series_arr = list(map(lambda col: df[col], label_arr))\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        legend=dict(orientation=\"h\"),\n",
    "        xaxis=dict(type='date'),\n",
    "        yaxis=dict(\n",
    "            title=y_axis_label,\n",
    "            showticklabels= not seperate_y_axis,\n",
    "            type=scale\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    y_axis_config = dict(\n",
    "        overlaying='y',\n",
    "        showticklabels=False,\n",
    "        type=scale )\n",
    "    \n",
    "    visibility = 'visible'\n",
    "    if initial_hide:\n",
    "        visibility = 'legendonly'\n",
    "        \n",
    "    # Form Trace For Each Series\n",
    "    trace_arr = []\n",
    "    for index, series in enumerate(series_arr):\n",
    "        trace = go.Scatter(\n",
    "            x=series.index, \n",
    "            y=series, \n",
    "            name=label_arr[index],\n",
    "            visible=visibility\n",
    "        )\n",
    "        \n",
    "        # Add seperate axis for the series\n",
    "        if seperate_y_axis:\n",
    "            trace['yaxis'] = 'y{}'.format(index + 1)\n",
    "            layout['yaxis{}'.format(index + 1)] = y_axis_config    \n",
    "        trace_arr.append(trace)\n",
    "\n",
    "    fig = go.Figure(data=trace_arr, layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest of brevity, I won't go too far into how this helper function works.  Check out the documentation for [Pandas](http://pandas.pydata.org/) and [Plotly](https://plot.ly/) if you would like to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function defined, we can compare our pricing datasets like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:01.567015Z",
     "start_time": "2017-12-06T08:01:01.036081Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot all of the BTC exchange prices\n",
    "df_scatter(btc_usd_datasets, 'Bitcoin Price (USD) By Exchange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Aggregate the Pricing Data\n",
    "We can see that, although the four series follow roughly the same path, there are various irregularities in each that we'll want to get rid of.\n",
    "\n",
    "Let's remove all of the zero values from the dataframe, since we know that the price of Bitcoin has never been equal to zero in the timeframe that we are examining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:01.584542Z",
     "start_time": "2017-12-06T08:01:01.570193Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove \"0\" values\n",
    "#df.replace(val, np.nan, inplace=True/False)\n",
    "#***YOUR CODE HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we re-chart the dataframe, we'll see a much cleaner looking chart without the spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:02.149787Z",
     "start_time": "2017-12-06T08:01:01.587042Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the revised dataframe\n",
    "# df_scatter( df, 'Title of chart)\n",
    "#***YOUR CODE HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate a new column, containing the daily average Bitcoin price across all of the exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:02.157872Z",
     "start_time": "2017-12-06T08:01:02.152766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average BTC price as a new column\n",
    "btc_usd_datasets['avg_btc_price_usd'] = btc_usd_datasets.#some aggregate function...()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new column is our Bitcoin pricing index!  Let's chart that column to make sure it looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:02.327167Z",
     "start_time": "2017-12-06T08:01:02.160490Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the average BTC price\n",
    "btc_trace = go.Scatter(x=btc_usd_datasets.index, y=btc_usd_datasets['avg_btc_price_usd'])\n",
    "py.iplot([btc_trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, looks good.  We'll use this aggregate pricing series later on, in order to convert the exchange rates of other cryptocurrencies to USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Altcoin Pricing Data\n",
    "Now that we have a solid time series dataset for the price of Bitcoin, let's pull in some data on non-Bitcoin cryptocurrencies, commonly referred to as altcoins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Poloniex API Helper Functions\n",
    "\n",
    "For retrieving data on cryptocurrencies we'll be using the [Poloniex API](https://poloniex.com/support/api/).  To assist in the altcoin data retrieval, we'll define two helper functions to download and cache JSON data from this API.\n",
    "\n",
    "First, we'll define `get_json_data`, which will download and cache JSON data from a provided URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:02.348136Z",
     "start_time": "2017-12-06T08:01:02.330199Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_json_data(json_url, file_name):\n",
    "    '''Download and cache JSON data, return as a dataframe.'''\n",
    "    cache_path = '{}{}.pkl'.format(data_dir, file_name)\n",
    "    try:        \n",
    "        f = open(cache_path, 'rb')\n",
    "        df = pickle.load(f)   \n",
    "        print('Loaded {} from cache'.format(file_name))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {}'.format(json_url))\n",
    "        df = pd.read_json(json_url)\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached response at {}'.format(cache_path))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a function to format Poloniex API HTTP requests and call our new `get_json_data` function to save the resulting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:01:39.304233Z",
     "start_time": "2017-12-06T08:01:39.276226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_polo_url = 'https://poloniex.com/public?command=returnChartData&currencyPair={}&start={}&end={}&period={}'\n",
    "start_date = datetime.strptime('2015-01-01', '%Y-%m-%d') # get data from the start of 2015\n",
    "end_date = datetime.now() # up until today\n",
    "pediod = 86400 # pull daily data (86,400 seconds per day)\n",
    "\n",
    "def get_crypto_data(poloniex_pair):\n",
    "    '''Retrieve cryptocurrency data from poloniex'''\n",
    "    json_url = base_polo_url.format(poloniex_pair, start_date.timestamp(), end_date.timestamp(), pediod)\n",
    "    data_df = get_json_data(json_url, poloniex_pair)\n",
    "    data_df = data_df.set_index('date')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take a cryptocurrency pair string (such as 'BTC_ETH') and return the dataframe containing the historical exchange rate of the two currencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Trading Data From Poloniex\n",
    "Most altcoins cannot be bought directly with USD; to acquire these coins individuals often buy Bitcoins and then trade the Bitcoins for altcoins on cryptocurrency exchanges.  For this reason we'll be downloading the exchange rate to BTC for each coin, and then we'll use our existing BTC pricing data to convert this value to USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll download exchange data for nine of the top cryptocurrencies -\n",
    "[Ethereum](https://www.ethereum.org/), [Litecoin](https://litecoin.org/), [Ripple](https://ripple.com/), [Ethereum Classic](https://ethereumclassic.github.io/), [Stellar](https://www.stellar.org/), [Dashcoin](http://dashcoin.info/), [Siacoin](http://sia.tech/), [Monero](https://getmonero.org/), and [NEM](https://www.nem.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:22.043871Z",
     "start_time": "2017-12-06T08:01:43.730285Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "altcoins = ['ETH','LTC','XRP','ETC','STR','DASH','SC','XMR','XEM']\n",
    "\n",
    "altcoin_data = {}\n",
    "for altcoin in altcoins:\n",
    "    coinpair = 'BTC_{}'.format(altcoin)\n",
    "    crypto_price_df = get_crypto_data(coinpair)\n",
    "    altcoin_data[altcoin] = crypto_price_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dictionary of 9 dataframes, each containing the historical daily average exchange prices between the altcoin and Bitcoin.\n",
    "\n",
    "We can preview the last few rows of the Ethereum price table to make sure it looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:39.015792Z",
     "start_time": "2017-12-06T08:02:38.977963Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "altcoin_data['ETH'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Prices to USD\n",
    "\n",
    "Since we now have the exchange rate for each cryptocurrency to Bitcoin, and we have the Bitcoin/USD historical pricing index, we can directly calculate the USD price series for each altcoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:40.016731Z",
     "start_time": "2017-12-06T08:02:39.981653Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate USD Price as a new column in each altcoin dataframe\n",
    "for altcoin in altcoin_data.keys():\n",
    "    altcoin_data[altcoin]['price_usd'] =  altcoin_data[altcoin]['weightedAverage'] * btc_usd_datasets['avg_btc_price_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've created a new column in each altcoin dataframe with the USD prices for that coin.\n",
    "\n",
    "Next, we can re-use our `merge_dfs_on_column` function from earlier to create a combined dataframe of the USD price for each cryptocurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:41.088501Z",
     "start_time": "2017-12-06T08:02:41.076368Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge USD price of each altcoin into single dataframe \n",
    "combined_df = merge_dfs_on_column(list(altcoin_data.values()), list(altcoin_data.keys()), 'price_usd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy.  Now let's also add the Bitcoin prices as a final column to the combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:41.846559Z",
     "start_time": "2017-12-06T08:02:41.840868Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add BTC price to the dataframe\n",
    "combined_df['BTC'] = btc_usd_datasets['avg_btc_price_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have a single dataframe containing daily USD prices for the ten cryptocurrencies that we're examining.\n",
    "\n",
    "Let's reuse our `df_scatter` function from earlier to chart all of the cryptocurrency prices against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:43.187112Z",
     "start_time": "2017-12-06T08:02:42.517427Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chart all of the altocoin prices\n",
    "df_scatter(combined_df, 'Cryptocurrency Prices (USD)', seperate_y_axis=False, y_axis_label='Coin Value (USD)', scale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! This graph gives a pretty solid \"big picture\" view of how the exchange rates of each currency have varied over the past few years.  \n",
    "\n",
    "> Note that we're using a logarithmic y-axis scale in order to compare all of currencies on the same plot.  You are welcome to try out different parameters values here (such as `scale='linear'`) to get different perspectives on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Correlation Values of The Cryptocurrencies\n",
    "You might notice is that the cryptocurrency exchange rates, despite their wildly different values and volatility, seem to be slightly correlated. Especially since the spike in April 2017, even many of the smaller fluctuations appear to be occurring in sync across the entire market.  \n",
    "\n",
    "A visually-derived hunch is not much better than a guess until we have the stats to back it up.\n",
    "\n",
    "We can test our correlation hypothesis using the Pandas `corr()` method, which computes a Pearson correlation coefficient for each column in the dataframe against each other column.\n",
    "\n",
    "Computing correlations directly on a non-stationary time series (such as raw pricing data) can give biased correlation values.  We will work around this by using the `pct_change()` method, which will convert each cell in the dataframe from an absolute price value to a daily return percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations in 2016\n",
    "First we'll calculate correlations for 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:43.737228Z",
     "start_time": "2017-12-06T08:02:43.679256Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the pearson correlation coefficients for altcoins in 2016\n",
    "combined_df_2016 = combined_df[\"***YOUR CODE HERE***\"]\n",
    "combined_df_2016.pct_change().corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These correlation coefficients are all over the place.  Coefficients close to 1 or -1 mean that the series' are strongly correlated or inversely correlated respectively, and coefficients close to zero mean that the values tend to fluctuate independently of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Visualization\n",
    "To help visualize these results, we'll create one more helper visualization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:44.151523Z",
     "start_time": "2017-12-06T08:02:44.131192Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_heatmap(df, title, absolute_bounds=True):\n",
    "    '''Plot a correlation heatmap for the entire dataframe'''\n",
    "    heatmap = go.Heatmap(\n",
    "        z=df.corr(method='pearson').as_matrix(),\n",
    "        x=df.columns,\n",
    "        y=df.columns,\n",
    "        colorbar=dict(title='Pearson Coefficient'),\n",
    "    )\n",
    "    \n",
    "    layout = go.Layout(title=title)\n",
    "    \n",
    "    if absolute_bounds:\n",
    "        heatmap['zmax'] = 1.0\n",
    "        heatmap['zmin'] = -1.0\n",
    "        \n",
    "    fig = go.Figure(data=[heatmap], layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:44.447188Z",
     "start_time": "2017-12-06T08:02:44.430818Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_heatmap(combined_df_2016.pct_change(), \"Cryptocurrency Correlations in 2016\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dark red values represent strong correlations (note that each currency is, obviously, strongly correlated with itself), and the dark blue values represent strong inverse correlations.  All of the light blue/orange/gray/tan colors in-between represent varying degrees of weak/non-existent correlations.\n",
    "\n",
    "What does this chart tell us? Essentially, it shows that there was very little statistically significant linkage between how the prices of different cryptocurrencies fluctuated during 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations in 2017\n",
    "Now, to test our hypothesis that the cryptocurrencies have become more correlated in recent months, let's repeat the same test using only the data from 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:45.096012Z",
     "start_time": "2017-12-06T08:02:45.057790Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_df_2017 = combined_df[\"***YOUR CODE HERE***\"]\n",
    "combined_df_2017.pct_change().corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are somewhat more significant correlation coefficients.  Strong enough to use as the sole basis for an investment? Certainly not.  \n",
    "\n",
    "It is notable, however, that almost all of the cryptocurrencies have become more correlated with each other across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T08:02:45.825147Z",
     "start_time": "2017-12-06T08:02:45.812025Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_heatmap(combined_df_2017.pct_change(), \"Cryptocurrency Correlations in 2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. That's rather interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is this happening?\n",
    "\n",
    "Good question.  I'm really not sure.  \n",
    "\n",
    "The most immediate explanation that comes to mind is that **hedge funds have recently begun publicly trading in crypto-currency markets**[^1][^2].  These funds have vastly more capital to play with than the average trader, so if a fund is hedging their bets across multiple cryptocurrencies, and using similar trading strategies for each based on independent variables (say, the stock market), it could make sense that this trend would emerge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Depth - XRP and STR\n",
    "For instance, one noticeable trait of the above chart is that XRP (the token for [Ripple](https://ripple.com/)), is the least correlated cryptocurrency.  The notable exception here is with STR (the token for [Stellar](https://www.stellar.org/), officially known as \"Lumens\"), which has a stronger (0.62) correlation with XRP.  \n",
    "\n",
    "What is interesting here is that Stellar and Ripple are both fairly similar fintech platforms aimed at reducing the friction of international money transfers between banks.  \n",
    "\n",
    "It is conceivable that some big-money players and hedge funds might be using similar trading strategies for their investments in Stellar and Ripple, due to the similarity of the blockchain services that use each token. This could explain why XRP is so much more heavily correlated with STR than with the other cryptocurrencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "\n",
    "This explanation is, however, largely speculative.  **Maybe you can do better**.  With the foundation we've made here, there are hundreds of different paths to take to continue searching for stories within the data.  \n",
    "\n",
    "Here are some ideas:\n",
    "\n",
    "- Add data from more cryptocurrencies to the analysis.\n",
    "- Adjust the time frame and granularity of the correlation analysis, for a more fine or coarse grained view of the trends. \n",
    "- Search for trends in trading volume and/or blockchain mining data sets.  The buy/sell volume ratios are likely more relevant than the raw price data if you want to predict future price fluctuations.\n",
    "- Add pricing data on stocks, commodities, and fiat currencies to determine which of them correlate with cryptocurrencies (but please remember the old adage that \"Correlation does not imply causation\").\n",
    "- Quantify the amount of \"buzz\" surrounding specific cryptocurrencies using Event Registry, GDLELT, and Google Trends. \n",
    "- Train a predictive machine learning model on the data to predict tomorrow's prices.  If you're more ambitious, you could even try doing this with a recurrent neural network (RNN).\n",
    "- Use your analysis to create an automated \"Trading Bot\" on a trading site such as Poloniex or Coinbase, using their respective trading APIs.  Be careful: a poorly optimized trading bot is an easy way to lose your money quickly.\n",
    "- **Share your findings!**  The best part of Bitcoin, and of cryptocurrencies in general, is that their decentralized nature makes them more free and democratic than virtually any other market.  Open source your analysis, participate in the community, maybe write a blog post about it.\n",
    "\n",
    "Hopefully, now you have the skills to do your own analysis and to think critically about any speculative cryptocurrency articles you might read in the near future, especially those written without any data to back up the provided predictions.\n",
    "\n",
    "Thanks for reading, and feel free to comment below with any ideas, suggestions, or criticisms regarding this tutorial.  I've got second (and potentially third) part in the works, which will likely be following through on some of same the ideas listed above, so stay tuned for more in the coming weeks.\n",
    "\n",
    "[^1]: http://fortune.com/2017/07/26/bitcoin-cryptocurrency-hedge-fund-sequoia-andreessen-horowitz-metastable/\n",
    "[^2]: https://www.forbes.com/sites/laurashin/2017/07/12/crypto-boom-15-new-hedge-funds-want-in-on-84000-returns/#7946ab0d416a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
